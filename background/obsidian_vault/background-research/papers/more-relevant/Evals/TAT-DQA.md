# Towards Complex Document Understanding By Discrete Reasoning
## Reference

https://arxiv.org/abs/2207.11871

## Summary

A new Document VQA composed of 3,067 document pages comprising semi-structured table(s) and unstructured text as well as 16,558 question-answer pairs. It is an extension of [[TAT-QA]]. It is sampled from real-world high-quality financial reports (mostly dated between 2018 and 2020) and each document contains both tabular and textual data. In TAT-QA, the hybrid context (table and text) are all selected and sorted manually by human experts from financial reports in PDF format. In TAT-DQA, they add multiple tables that may or may not be related to the text and questions.

## Notes

Construction of QA:
- Borrow the question-answer (Q-A) pairs from the previous TAT-QA dataset, which are generated by human experts in finance. Then cleaned up with other human experts in finance to generate some more Q-A pairs, and meanwhile remove a few pairs with errors we have found during data preparation.
- 4 types of answers:
	- Span: The answer is a continuous text in the document.
	-  Spans: Also called â€œMulti-span" and is a set of non-contiguous spans in the document.
	- Counting: The answer is an integer that is computed by performing counting.
	- Arithmetic: The answer is a numerical value that is obtained by performing arithmetic operations such as addition, subtraction, multiplication, division and their compositions.
- Process each retaining document page after filtering relevant ones to obtain the text with a bounding box using Apache PDFBox2 for PDF files or an OCR engine for the images. Each document page is converted to a list of text blocks and each text block has a list of words, with every block or word framed by its own bounding box. The questions about a particular document belong to only one of the splits.
	- Stats:
		- Average document length: 550.29 words
		- Number of pages per document: 1.33 (3 at most)

Discovered empirically that processing tabular data separately would significantly improve model performance.

They also use a multi-head predictor to guess the question type and fine tune the process based on each type.