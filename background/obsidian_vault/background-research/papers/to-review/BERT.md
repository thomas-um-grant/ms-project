# BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
## Reference

https://arxiv.org/abs/1810.04805

## Summary
